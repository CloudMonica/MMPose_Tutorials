{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63f1dd0a-8685-40fd-b5d7-3218f97ac899",
   "metadata": {},
   "source": [
    "# 2D人体关键点 预训练模型预测-命令行\n",
    "\n",
    "参考文档：https://github.com/open-mmlab/mmpose/blob/master/demo/docs/2d_human_pose_demo.md\n",
    "\n",
    "作者：同济子豪兄 2022-06-06\n",
    "\n",
    "如果报错`CUDA out of memory.`则重启前面几个代码的`kernel`即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff424e2-8d49-4f7c-8e81-24a957d1b7b9",
   "metadata": {},
   "source": [
    "## 进入 MMPose 主目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c24d56aa-5528-4561-bb1c-33bcffe2c852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.circleci',\n",
       " '.dev_scripts',\n",
       " '.github',\n",
       " '.gitignore',\n",
       " '.pre-commit-config.yaml',\n",
       " '.pylintrc',\n",
       " '.readthedocs.yml',\n",
       " 'CITATION.cff',\n",
       " 'LICENSE',\n",
       " 'MANIFEST.in',\n",
       " 'README.md',\n",
       " 'README_CN.md',\n",
       " 'configs',\n",
       " 'demo',\n",
       " 'docker',\n",
       " 'docs',\n",
       " 'mmpose',\n",
       " 'model-index.yml',\n",
       " 'pytest.ini',\n",
       " 'requirements.txt',\n",
       " 'requirements',\n",
       " 'resources',\n",
       " 'setup.cfg',\n",
       " 'setup.py',\n",
       " 'tests',\n",
       " 'tools',\n",
       " 'mmpose.egg-info',\n",
       " 'checkpoints',\n",
       " 'outputs',\n",
       " 'data']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('mmpose')\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c272e015-6112-495d-b407-531fcf46b9bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 自顶向下`top_down`算法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d4b2a2-cdf0-40c9-99d6-e5c0bdfae73a",
   "metadata": {},
   "source": [
    "### 用目标检测预测框作为`top_down`算法的输入框输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cddc453-bb4d-49e8-8b70-b3be1154712c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from http path: https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w48_coco_256x192-b9e0b3ab_20200708.pth\n"
     ]
    }
   ],
   "source": [
    "!python demo/top_down_img_demo_with_mmdet.py \\\n",
    "        demo/mmdetection_cfg/faster_rcnn_r50_fpn_coco.py \\\n",
    "        https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth \\\n",
    "        configs/body/2d_kpt_sview_rgb_img/topdown_heatmap/coco/hrnet_w48_coco_256x192.py \\\n",
    "        https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w48_coco_256x192-b9e0b3ab_20200708.pth \\\n",
    "        --img data/TongjiDancer.png \\\n",
    "        --out-img-root outputs/B2/B2_1_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee67f933-2a6f-4146-88b5-c53d1399e866",
   "metadata": {},
   "source": [
    "### 用标注框作为`top_down`算法的输入框输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd1ae34f-1fc2-4374-8ad8-c62169c2a4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w48_coco_256x192-b9e0b3ab_20200708.pth\n"
     ]
    }
   ],
   "source": [
    "!python demo/top_down_img_demo.py \\\n",
    "        configs/body/2d_kpt_sview_rgb_img/topdown_heatmap/coco/hrnet_w48_coco_256x192.py \\\n",
    "        https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w48_coco_256x192-b9e0b3ab_20200708.pth \\\n",
    "        --img-root tests/data/coco/ \\\n",
    "        --json-file tests/data/coco/test_coco.json \\\n",
    "        --out-img-root outputs/B2/B2_2_gt_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7600f5-c4be-47f5-95b4-147213edabed",
   "metadata": {},
   "source": [
    "### 单帧输入模型的视频预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9928a78-d7f2-42b1-a3fa-e64035e4a4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model...\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w48_coco_256x192-b9e0b3ab_20200708.pth\n",
      "Running inference...\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 99/99, 3.9 task/s, elapsed: 25s, ETA:     0s\n"
     ]
    }
   ],
   "source": [
    "!python demo/top_down_video_demo_with_mmdet.py \\\n",
    "        demo/mmdetection_cfg/faster_rcnn_r50_fpn_coco.py \\\n",
    "        https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth \\\n",
    "        configs/body/2d_kpt_sview_rgb_img/topdown_heatmap/coco/hrnet_w48_coco_256x192.py \\\n",
    "        https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w48_coco_256x192-b9e0b3ab_20200708.pth \\\n",
    "        --video-path data/mot_people_short.mp4 \\\n",
    "        --bbox-thr 0.8 \\\n",
    "        --out-video-root outputs/B2/B2_3_video_single_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd383ab-0135-4a44-9c3d-659f32b02954",
   "metadata": {},
   "source": [
    "### 多帧输入模型的视频预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c42b28-a6fa-4495-8142-02e0251691e3",
   "metadata": {},
   "source": [
    "使用`--use-multi-frames`参数，将视频前后多帧画面输入模型用于姿态预测。\n",
    "\n",
    "使用`--online`参数，仅输入该帧之前的帧，不输入该帧之后的帧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01931340-af91-4d33-922c-1cad7888865c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model...\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmpose/top_down/posewarper/hrnet_w48_posetrack18_384x288_posewarper_stage2-4abf88db_20211130.pth\n",
      "Running inference...\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 99/99, 0.5 task/s, elapsed: 183s, ETA:     0s\n"
     ]
    }
   ],
   "source": [
    "!python demo/top_down_video_demo_with_mmdet.py \\\n",
    "        demo/mmdetection_cfg/faster_rcnn_r50_fpn_coco.py \\\n",
    "        https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth \\\n",
    "        configs/body/2d_kpt_sview_rgb_vid/posewarper/posetrack18/hrnet_w48_posetrack18_384x288_posewarper_stage2.py \\\n",
    "        https://download.openmmlab.com/mmpose/top_down/posewarper/hrnet_w48_posetrack18_384x288_posewarper_stage2-4abf88db_20211130.pth  \\\n",
    "        --video-path data/mot_people_short.mp4 \\\n",
    "        --out-video-root outputs/B2/B2_4_multi_frames \\\n",
    "        --use-multi-frames --online"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3d85ba-ad01-4c1b-8e15-07642829e028",
   "metadata": {},
   "source": [
    "### 全图输入模型的视频预测\n",
    "\n",
    "不提取人体检测框，直接将全图输入至姿态估计模型中。\n",
    "\n",
    "仅适用于视频中人体始终在画面中央的场景。\n",
    "\n",
    "仅适用于单人。\n",
    "\n",
    "扩展阅读：Mediapipe Blaze Pose单人实时人体姿态估计：https://www.bilibili.com/video/BV1dL4y1h7Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b698955a-ef57-41be-aa6d-3effacb90f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model...\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmpose/top_down/vipnas/vipnas_res50_coco_256x192-cc43b466_20210624.pth\n",
      "Downloading: \"https://download.openmmlab.com/mmpose/top_down/vipnas/vipnas_res50_coco_256x192-cc43b466_20210624.pth\" to /home/featurize/.cache/torch/hub/checkpoints/vipnas_res50_coco_256x192-cc43b466_20210624.pth\n",
      "100%|██████████████████████████████████████| 28.0M/28.0M [00:00<00:00, 89.6MB/s]\n",
      "Running inference...\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 645/729, 17.3 task/s, elapsed: 37s, ETA:     5s\n"
     ]
    }
   ],
   "source": [
    "!python demo/top_down_video_demo_full_frame_without_det.py \\\n",
    "        configs/body/2d_kpt_sview_rgb_img/topdown_heatmap/coco/vipnas_res50_coco_256x192.py \\\n",
    "         https://download.openmmlab.com/mmpose/top_down/vipnas/vipnas_res50_coco_256x192-cc43b466_20210624.pth \\\n",
    "        --video-path data/solo_dance.mp4 \\\n",
    "        --out-video-root outputs/B2/B2_5_full_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd36abfc-31f5-4e52-866d-87e9e670e718",
   "metadata": {},
   "source": [
    "## 自底向上`Bottom-Up`算法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5078404b-c30d-49f8-bb97-a32045026523",
   "metadata": {},
   "source": [
    "### 单张图像预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d434a232-411c-44f3-ae64-f7117b8dcade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from http path: https://download.openmmlab.com/mmpose/bottom_up/hrnet_w32_coco_512x512-bcb8c247_20200816.pth\n",
      "Downloading: \"https://download.openmmlab.com/mmpose/bottom_up/hrnet_w32_coco_512x512-bcb8c247_20200816.pth\" to /home/featurize/.cache/torch/hub/checkpoints/hrnet_w32_coco_512x512-bcb8c247_20200816.pth\n",
      "100%|█████████████████████████████████████████| 109M/109M [00:01<00:00, 104MB/s]\n",
      "[                                                  ] 0/1, elapsed: 0s, ETA:/home/featurize/work/MMPose教程/mmpose/mmpose/core/post_processing/group.py:240: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  y = ind // W\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 1/1, 0.1 task/s, elapsed: 13s, ETA:     0s\n"
     ]
    }
   ],
   "source": [
    "!python demo/bottom_up_img_demo.py \\\n",
    "        configs/body/2d_kpt_sview_rgb_img/associative_embedding/coco/hrnet_w32_coco_512x512.py \\\n",
    "        https://download.openmmlab.com/mmpose/bottom_up/hrnet_w32_coco_512x512-bcb8c247_20200816.pth \\\n",
    "        --img data/TongjiDancer.png \\\n",
    "        --out-img-root outputs/B2/B2_6_bottom_up_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbca5c2-d7b3-4e93-b1f1-5b3fadcb0c2c",
   "metadata": {},
   "source": [
    "### 视频预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5eba779-3a45-4c11-baea-ced185ab07ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from http path: https://download.openmmlab.com/mmpose/bottom_up/hrnet_w32_coco_512x512-bcb8c247_20200816.pth\n",
      "/home/featurize/work/MMPose教程/mmpose/mmpose/core/post_processing/group.py:240: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  y = ind // W\n"
     ]
    }
   ],
   "source": [
    "!python demo/bottom_up_video_demo.py \\\n",
    "        configs/body/2d_kpt_sview_rgb_img/associative_embedding/coco/hrnet_w32_coco_512x512.py \\\n",
    "        https://download.openmmlab.com/mmpose/bottom_up/hrnet_w32_coco_512x512-bcb8c247_20200816.pth \\\n",
    "        --video-path data/mot_people_short.mp4 \\\n",
    "        --out-video-root outputs/B2/B2_7_bottom_up_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b76e65-1fe0-4bac-b715-063d52c22895",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
